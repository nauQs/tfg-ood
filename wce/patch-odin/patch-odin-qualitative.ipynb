{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "excess-priest",
   "metadata": {},
   "source": [
    "# Patch-based ODIN qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passive-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import imageio\n",
    "from skimage import transform,io\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from collections import Counter \n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "\n",
    "from PIL import ImageFile, Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "if False: # only for JupyterLab with GPUs environment\n",
    "    import sys\n",
    "    sys.path.insert(0, '/notebooks/')\n",
    "    sys.path.insert(0, '../')\n",
    "    from CapsuleLib.utils import gpu_config, availableGPU\n",
    "    gpuid = gpu_config(False, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-bowling",
   "metadata": {},
   "source": [
    "## Paths setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "popular-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "NORMAL_IMAGES_PATH = \"/data/capri/polyp_db_v3/normal_dbv1\"  # set paths here!\n",
    "OOD_IMAGES_PATH = \"/notebooks/Arnau/patch-self-supervised/data/ood-images\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-rouge",
   "metadata": {},
   "source": [
    "##  Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "living-tunisia",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "PATCH_SIZE = (64,64)\n",
    "IM_SIZE = 256\n",
    "TEMP = 1000\n",
    "K = 20\n",
    "FOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-hollywood",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = NORMAL_IMAGES_PATH\n",
    "filepaths, videos = [], []\n",
    "for image in os.listdir(path):\n",
    "    if image.endswith('.png'):\n",
    "        image_id = image[:3]\n",
    "        filepaths.append(os.path.join(path,image))\n",
    "        videos.append(image_id)\n",
    "df = pd.DataFrame({\"path\": filepaths, \"video\":videos})\n",
    "df['video'] = df['video'].astype(int)\n",
    "\n",
    "folds = pd.read_csv('3fold.csv')\n",
    "\n",
    "path = OOD_IMAGES_PATH\n",
    "\n",
    "filepaths, image_ids = [], []\n",
    "for image in os.listdir(path):\n",
    "    if image.endswith('.png'):\n",
    "        image_id = image.split('-')[0][-3:]\n",
    "        filepaths.append(os.path.join(path,image))\n",
    "        image_ids.append(image_id)\n",
    "df_ood = pd.DataFrame({\"path\": filepaths, \"image\":image_ids})\n",
    "\n",
    "def rotate_image(image):\n",
    "    return np.rot90(image, np.random.choice([-1, 0, 1, 2]))\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255., vertical_flip=True,\n",
    "    horizontal_flip=True,preprocessing_function=rotate_image)\n",
    "\n",
    "normal_gen=datagen.flow_from_dataframe(dataframe=df, x_col=\"path\", class_mode=None, \n",
    "    target_size=(IM_SIZE,IM_SIZE), batch_size=BATCH_SIZE, shuffle=True, seed=1)\n",
    "\n",
    "ood_gen=datagen.flow_from_dataframe(dataframe=df_ood, x_col=\"path\", class_mode=None, \n",
    "    target_size=(IM_SIZE,IM_SIZE), batch_size=BATCH_SIZE, shuffle=True, seed=1)\n",
    "\n",
    "model = keras.models.load_model(f'models/patches-classifier-{K}-t1000-f{FOLD}.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technical-robin",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-brisbane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_msp(image_batch):\n",
    "    \"\"\"\n",
    "    Returns the list of MSP given a batch of images\n",
    "    \"\"\"\n",
    "    softmax_probs = model.predict(image_batch)\n",
    "    return 1 - np.max(softmax_probs, axis=1)\n",
    "\n",
    "def sliding_windows(image, mode=\"16\"):\n",
    "    \"\"\"\n",
    "    Returns overlapping 64x64 patches from a 256x256 image\n",
    "    \"\"\"\n",
    "    windows = []\n",
    "    if mode==\"16\":\n",
    "        for y in range(32, 192, 44):\n",
    "            for x in range(32, 192, 44):\n",
    "                windows.append(image[y:y+64, x:x+64])\n",
    "    elif mode==\"28\":\n",
    "        for x in range(51,150, 46):\n",
    "            windows.append(image[4:68, x:x+64])\n",
    "        for y in range(28, 192, 46):\n",
    "            for x in range(28, 192, 46):\n",
    "                windows.append(image[y:y+64, x:x+64])\n",
    "        for x in range(51,150, 46):\n",
    "            windows.append(image[188:252, x:x+64])\n",
    "        for y in range(51,150, 46):\n",
    "            windows.append(image[y:y+64, 4:68])\n",
    "        for y in range(51,150, 46):\n",
    "            windows.append(image[y:y+64, 188:252])\n",
    "    return np.array(windows)\n",
    "\n",
    "def perturb_images(images, epsilon=0.0005):\n",
    "    \"\"\"\n",
    "    Perturbs a batch of image for a given epsilon magnitude\n",
    "    \"\"\"\n",
    "    \n",
    "    test_ds_var = tf.Variable(images, trainable=True)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(test_ds_var)\n",
    "        logits = model(test_ds_var, training=False)\n",
    "        loss = -tf.reduce_mean(tf.reduce_max(logits, axis=1))\n",
    "\n",
    "    gradients = tape.gradient(loss, test_ds_var)\n",
    "    gradients = tf.math.greater_equal(gradients, 0)\n",
    "    gradients = tf.cast(gradients, tf.float32)\n",
    "    gradients = (gradients - 0.5) * 2\n",
    "\n",
    "    static_tensor = tf.convert_to_tensor(test_ds_var) - epsilon * gradients\n",
    "    static_tensor = tf.clip_by_value(static_tensor, 0., 255.)\n",
    "    \n",
    "    return static_tensor\n",
    "\n",
    "def get_ordered_patches(image, epsilon=0.0005, mode=\"16\"):\n",
    "    \"\"\"\n",
    "    Returns list of patches, from most abnormal to most normal\n",
    "    \"\"\"\n",
    "    patches = sliding_windows(image, mode=mode)\n",
    "    if epsilon==0:\n",
    "        msp_patches = get_msp(patches)\n",
    "    else:\n",
    "        msp_patches = get_msp(perturb_images(patches, epsilon))\n",
    "        \n",
    "    return msp_patches, [x for _, x in sorted(zip(msp_patches, patches), reverse=True)]\n",
    "\n",
    "def plot_strip(image_strip):\n",
    "    \"\"\"\n",
    "    Plot strip of images\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,len(image_strip), figsize=(len(image_strip),2))\n",
    "    for i, im in enumerate(image_strip):\n",
    "        ax[i].imshow(im)\n",
    "        ax[i].axis('off')\n",
    "\n",
    "def get_16_heatmap(msp_patches):\n",
    "    \"\"\"\n",
    "    Returns heatmap of the given patches\n",
    "    \"\"\"\n",
    "    heatmap = np.zeros((256,256))\n",
    "    count = np.zeros((256,256))\n",
    "    i = 0\n",
    "    windows = []\n",
    "    for y in range(32, 192, 44):\n",
    "        for x in range(32, 192, 44):\n",
    "            heatmap[y:y+64, x:x+64] += msp_patches[i]\n",
    "            count[y:y+64, x:x+64] += 1\n",
    "            i += 1\n",
    "    count = np.clip(count,1.,np.inf)   \n",
    "\n",
    "    return heatmap/count\n",
    "\n",
    "def get_28_heatmap(msp_patches):\n",
    "    \"\"\"\n",
    "    Returns 28-patches heatmap of the given patches\n",
    "    \"\"\"\n",
    "    heatmap = np.zeros((256,256))\n",
    "    count = np.zeros((256,256))\n",
    "    i = 0\n",
    "    for x in range(51,150, 46):\n",
    "        heatmap[4:68, x:x+64] += msp_patches[i]\n",
    "        count[4:68, x:x+64] += 1\n",
    "        i += 1\n",
    "    for y in range(28, 192, 46):\n",
    "        for x in range(28, 192, 46):\n",
    "            heatmap[y:y+64, x:x+64] += msp_patches[i]\n",
    "            count[y:y+64, x:x+64] += 1\n",
    "            i += 1\n",
    "    for x in range(51,150, 46):\n",
    "            heatmap[188:252, x:x+64] += msp_patches[i]\n",
    "            count[188:252, x:x+64] += 1\n",
    "            i += 1\n",
    "    for y in range(51,150, 46):\n",
    "        heatmap[y:y+64, 4:68] += msp_patches[i]\n",
    "        count[y:y+64, 4:68] += 1\n",
    "        i += 1\n",
    "    for y in range(51,150, 46):\n",
    "        heatmap[y:y+64, 188:252] += msp_patches[i]\n",
    "        count[y:y+64, 188:252] += 1\n",
    "        i += 1\n",
    "    count = np.clip(count,1.,np.inf)\n",
    "    return heatmap/count\n",
    "\n",
    "def plot_heatmap(image, epsilon=0.0005, mode=\"16\"):\n",
    "    \"\"\"\n",
    "    Plots the heatmap of an image\n",
    "    \"\"\"\n",
    "    \n",
    "    msp_patches, _ = get_ordered_patches(image, epsilon, mode=mode)\n",
    "    \n",
    "    if mode ==\"16\":\n",
    "        hmax = sns.heatmap(get_16_heatmap(msp_patches), alpha=1,\n",
    "                cmap=\"Reds\", cbar=False, xticklabels=False, yticklabels=False, \n",
    "                       square=True, vmin=0.1, vmax=0.8)\n",
    "        hmax.imshow(image, alpha=0.6, zorder = 1) \n",
    "    \n",
    "    elif mode ==\"28\":\n",
    "        hmax = sns.heatmap(get_28_heatmap(msp_patches), alpha=1,\n",
    "                cmap=\"Reds\", cbar=False, xticklabels=False, yticklabels=False, \n",
    "                       square=True, vmin=0.2, vmax=1)\n",
    "        hmax.imshow(image, alpha=0.6, zorder = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-effect",
   "metadata": {},
   "source": [
    "## Patches strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "israeli-ireland",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = ood_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(8,8, figsize=(8,8))\n",
    "for i, image in enumerate(batch):\n",
    "    ax[i//8,i%8].imshow(image)\n",
    "    ax[i//8,i%8].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-office",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = batch[11]\n",
    "image = rotate_image(image)\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.savefig('qualitative/tfg-strip-wrong-image-2.png', bbox_inches='tight')\n",
    "plot_strip(get_ordered_patches(image, epsilon=0)[1])\n",
    "plt.savefig('qualitative/tfg-strip-wrong-patches-2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-consequence",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-burlington",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_heatmap(image)\n",
    "plt.savefig('qualitative/tfg-wrong-heatmap-2.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-resident",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image_paths = ['04562.png', # white tube\n",
    " '05720.png', # white tube + white blob\n",
    " '067_1_1_04043.png', # ???\n",
    " '04607.png', # white tube\n",
    " '00679.png', # ?????\n",
    " '064_1_2_04812.png', # metal tube?\n",
    " '003_1_021215.png', # ?????\n",
    " '04579.png', # white tube\n",
    " '05865.png', # white tube\n",
    " '064_2_010151.png'] # blood\n",
    "path = OOD_IMAGES_PATH\n",
    "\n",
    "example_images = []\n",
    "for image in example_image_paths:\n",
    "    pic = Image.open(os.path.join(path,image))\n",
    "    example_images.append(np.array(pic,dtype=\"float32\")/255)\n",
    "    \n",
    "fig, ax = plt.subplots(2,5, figsize=(10,4))\n",
    "for i, image in enumerate(example_images):\n",
    "    msp_patches, _ = get_ordered_patches(image, 0.0005)\n",
    "    \n",
    "    hmax = sns.heatmap(get_16_heatmap(msp_patches), alpha=1,\n",
    "            cmap=\"Reds\", cbar=False, xticklabels=False, yticklabels=False, \n",
    "                   square=True, vmin=0, vmax=0.8, ax=ax[i//5,i%5])\n",
    "    hmax.imshow(image, alpha=0.7, zorder = 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-gather",
   "metadata": {},
   "source": [
    "## Highest- and lowest-score images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.empty((0,256,256,3))\n",
    "scores = np.empty((0,))\n",
    "N = 1\n",
    "for n in range(N):\n",
    "    batch = ood_gen.next()\n",
    "    batch_scores = []\n",
    "    for image in batch:\n",
    "        patches = sliding_windows(image)\n",
    "        msp_patches = get_msp(perturb_images(patches, 0.001))\n",
    "\n",
    "        summary_patches = sum(sorted(msp_patches, reverse=True)[:5])/5.\n",
    "        batch_scores.append(summary_patches)\n",
    "    \n",
    "    images = np.concatenate([images, batch])\n",
    "    scores = np.concatenate([scores, batch_scores])\n",
    "    \n",
    "sorted_images = list(images[np.argsort(scores)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 5\n",
    "n = 5\n",
    "top_image = np.zeros((256, 256*n, 3))\n",
    "top_images = sorted_images[-n:]\n",
    "for i, image in enumerate(top_images):\n",
    "    top_image[:,i*256:(i+1)*256,:] += image\n",
    "plt.imshow(top_image)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'qualitative/patch-top-images.png', dpi=300, bbox_inches='tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "juvenile-pregnancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bot 5\n",
    "n = 5\n",
    "bot_image = np.zeros((256, 256*n, 3))\n",
    "bot_images = sorted_images[:n]\n",
    "for i, image in enumerate(bot_images):\n",
    "    bot_image[:,i*256:(i+1)*256,:] += image\n",
    "plt.imshow(bot_image)\n",
    "plt.axis('off')\n",
    "plt.savefig(f'qualitative/patch-bot-images.png', dpi=300, bbox_inches='tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-ivory",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
